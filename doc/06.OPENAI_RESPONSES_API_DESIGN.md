# OpenAI Responses API 集成方案

## 一、背景

OpenAI 推出了新的 **Responses API**，它结合了 Chat Completions API 的简洁性和 Assistants API 的工具使用功能，支持内置工具如：
- `web_search` - 网络搜索工具（实时获取最新信息）
- `file_search` - 文件搜索工具（从上传的文件中检索信息）

当前项目使用的是传统的 Chat Completions API，需要新增对 Responses API 的支持。

## 二、方案设计

### 2.1 方案选择

**方案A：新增独立的 Provider 类型**
- 优点：职责清晰，两种 API 完全分离
- 缺点：需要新增 provider 类型，配置和选择逻辑更复杂

**方案B：在现有 OpenAIProvider 中根据配置自动选择 API**
- 优点：复用现有代码，配置简单，用户无感知
- 缺点：一个 Provider 类承担两种 API 的实现

**采用方案：方案B（在现有 Provider 中支持）**

理由：
1. 用户使用体验更好，无需关心底层 API 差异
2. 代码复用性更高，减少重复代码
3. 可以根据模型或配置自动选择最合适的 API
4. 符合"最小化修改"的原则

### 2.2 实现策略

**自动判断策略：根据 model 字段自动选择 API**

- **使用 OpenAI 官方模型**：
  - 自动使用 Responses API
  - 支持内置工具（web_search、file_search）
  - 所有以 `gpt` 开头的模型（如 gpt-4o, gpt-4-turbo, gpt-3.5-turbo 等）
  - 所有以 `o1` 开头的模型（如 o1, o1-preview, o1-mini 等）
  
- **使用非 OpenAI 官方模型**（自定义模型或其他兼容模型）：
  - 使用传统的 Chat Completions API
  - 保持向后兼容，确保现有配置继续工作

**判断逻辑：**
- 如果 `model` 以 `gpt` 开头，使用 Responses API（所有 GPT 系列模型）
- 如果 `model` 以 `o1` 开头，使用 Responses API（所有 O1 系列模型）
- 如果 `model` 是其他名称，使用 Chat Completions API

### 2.3 技术实现

#### 2.3.1 类型定义扩展

```typescript
// src/types/chat-type.ts
export interface AIConfig {
  provider: 'openai' | 'anthropic' | 'custom'
  apiKey: string
  baseURL?: string
  model: string  // 根据 model 字段自动判断使用哪个 API
  temperature?: number
  maxTokens?: number
  // OpenAI 特定配置
  openai?: {
    organization?: string
  }
}

// 工具选择在聊天界面中控制，通过消息或请求参数传递
// 例如：在 streamChat 方法中增加 tools 参数
// API 选择根据 model 字段自动判断，无需额外配置
```

#### 2.3.2 Provider 实现

在 `OpenAIProvider` 中：
1. 添加 API 选择逻辑（根据 model 字段自动判断）
2. 实现 Responses API 的流式调用
3. 保持与现有 Chat Completions API 的接口兼容
4. OpenAI 官方模型默认启用 `web_search` 和 `file_search` 工具
5. 支持上层传入额外工具，与默认工具自动合并去重
6. 工具选择由聊天界面控制，通过请求参数传递（不在配置中持久化）

**API 选择方法：**
```typescript
private shouldUseResponsesAPI(config: AIConfig): boolean {
  const model = config.model.toLowerCase()
  
  // OpenAI 官方模型判断：所有以 gpt 或 o1 开头的模型
  // 包括：gpt-4o, gpt-4-turbo, gpt-3.5-turbo, gpt-4o-2024-xxx, o1, o1-preview 等
  return model.startsWith('gpt') || model.startsWith('o1')
}
```

#### 2.3.3 API 差异处理

**Chat Completions API:**
```typescript
client.chat.completions.create({
  model: config.model,
  messages: openaiMessages,
  stream: true
})
```

**Responses API:**
```typescript
// 工具通过请求参数传递（由聊天界面选择）
client.beta.responses.create({
  model: config.model,
  messages: openaiMessages,
  stream: true,
  tools: tools || []  // tools 参数从请求中获取，不在配置中
})
```

**工具选择机制：**
- OpenAI 官方模型（gpt 或 o1 开头）默认启用 `web_search` 和 `file_search` 两个工具
- 上层可以通过 `streamChat` 方法的扩展参数传递额外的工具列表
- 默认工具和上层传入的工具会自动合并并去重
- 非 OpenAI 官方模型只使用上层传入的工具（如果有）
- 不在 `AIConfig` 中持久化工具配置，每次请求可灵活选择

**响应格式差异：**
- Chat Completions: `chunk.choices[0]?.delta?.content`
- Responses API: 需要检查响应结构，可能包含工具调用结果

## 三、实现步骤

### 步骤1：扩展类型定义 ✅
- [x] 扩展 `streamChat` 方法签名，支持传递工具列表参数
- [x] 无需修改 `AIConfig` 类型（API 选择自动判断）

### 步骤2：实现 API 选择逻辑 ✅
- [x] 添加 `shouldUseResponsesAPI()` 方法判断使用哪个 API
- [x] 根据 `model` 字段自动判断：以 `gpt` 或 `o1` 开头 → Responses API，其他 → Chat Completions API
- [x] 判断逻辑简单：检查 model 是否以 `gpt` 或 `o1` 开头（不区分大小写）

### 步骤3：实现 Responses API 调用 ✅
- [x] 创建 `streamChatWithResponsesAPI()` 方法
- [x] 处理 Responses API 的流式响应
- [x] 处理工具调用结果（如 web_search 的引用）
- [x] 实现默认工具逻辑：OpenAI 官方模型自动启用 web_search（file_search 需要 vector_store_ids）
- [x] 实现工具合并逻辑：默认工具与上层传入工具合并去重

### 步骤4：重构现有代码 ✅
- [x] 将现有 `streamChat()` 方法重构为 `streamChatWithCompletionsAPI()`
- [x] 在 `streamChat()` 中根据选择调用对应方法
- [x] 保持接口兼容性

### 步骤5：测试验证 ✅
- [x] 测试 Chat Completions API（确保现有功能正常）
- [x] 测试 Responses API（新功能）
- [x] 测试自动选择逻辑
- [x] 测试工具调用（web_search）

**实现完成时间：** 2024年12月

**实现文件：**
- `src/main/providers/index.ts` - AIProvider 接口定义，添加 ToolType 类型和 options 参数
- `src/main/providers/openai-provider.ts` - OpenAIProvider 实现，支持自动切换 API

## 四、代码结构

```
src/main/providers/
├── index.ts                    # AIProvider 接口和工厂
├── openai-provider.ts         # OpenAIProvider（支持两种 API）
└── openai-responses-provider.ts # （可选）独立的 Responses API Provider
```

**推荐结构：**
- 在 `openai-provider.ts` 中实现两种 API 的支持
- 通过内部方法分离两种 API 的实现逻辑

## 五、注意事项

### 5.1 API 可用性
- Responses API 可能还在 Beta 阶段，需要确认 SDK 版本支持
- 某些模型可能只支持特定 API

### 5.2 工具使用
- 工具选择在聊天界面中控制，不在配置中持久化
- `web_search` 工具：由用户在聊天界面中选择是否启用
- `file_search` 工具：需要先上传文件到 OpenAI，由用户在聊天界面中选择
- 工具调用结果需要特殊处理（如显示引用来源）
- 每次请求可以灵活选择不同的工具组合

### 5.3 向后兼容
- 使用非 OpenAI 官方模型的配置自动使用 Chat Completions API，保持向后兼容
- 使用 OpenAI 官方模型的配置自动使用 Responses API
- 确保现有使用自定义模型或代理的配置继续正常工作
- baseURL 设置不影响 API 选择，仅影响请求地址

### 5.4 错误处理
- 如果 Responses API 不可用，应降级到 Chat Completions API
- 提供清晰的错误提示

## 六、配置示例

### 示例1：使用 GPT 系列模型（自动使用 Responses API）
```typescript
{
  provider: 'openai',
  model: 'gpt-4o',  // 所有以 gpt 开头的模型，自动使用 Responses API
  apiKey: 'xxx'
}
// 包括：gpt-4o, gpt-4-turbo, gpt-4, gpt-3.5-turbo, gpt-4o-2024-xxx 等
```

### 示例2：使用 O1 系列模型（自动使用 Responses API）
```typescript
{
  provider: 'openai',
  model: 'o1-preview',  // 所有以 o1 开头的模型，自动使用 Responses API
  apiKey: 'xxx',
  baseURL: 'https://api.openai.com/v1'  // baseURL 不影响 API 选择
}
// 包括：o1, o1-preview, o1-mini 等
// 工具选择在聊天界面中控制，通过请求参数传递
// streamChat(messages, config, callbacks, abortSignal, { tools: ['web_search'] })
```

### 示例3：使用自定义模型（使用传统 Chat Completions API）
```typescript
{
  provider: 'openai',
  model: 'custom-model-name',  // 不以 gpt 或 o1 开头，使用 Chat Completions API
  apiKey: 'xxx',
  baseURL: 'https://api.example.com/v1'  // 自定义地址
}
```

## 七、后续优化

1. **工具调用结果展示**
   - 在 UI 中显示 web_search 的引用来源
   - 支持文件搜索结果的展示

2. **性能优化**
   - 缓存工具调用结果
   - 优化流式响应处理

3. **配置管理**
   - API 选择完全自动化，无需用户配置
   - OpenAI 官方模型默认启用 web_search 和 file_search 工具
   - 上层可以传入额外工具，与默认工具自动合并
   - 工具选择在聊天界面中实时控制，不持久化
   - 系统根据 model 字段自动选择对应的 API
   - baseURL 仅用于指定请求地址，不影响 API 选择

